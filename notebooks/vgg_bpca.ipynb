{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucs1590/vgg_bpca/blob/master/notebooks/vgg_bpca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "L3yAF4A2R4z2"
      },
      "source": [
        "## VGG_BPCA\n",
        "Here we are using a VGG net with 19 layers with the dataset cifar 100.\n",
        "\n",
        "We are trying to reproduce the results of the paper [1] changing the max pooling layers for blocked based principal component analysis (BPCA) layers like the article [2] proposes.\n",
        "\n",
        "[1] https://arxiv.org/pdf/1706.05350.pdf\n",
        "\n",
        "[2] http://www.ic.uff.br/iwssip2010/Proceedings/nav/papers/paper_10.pdf\n",
        "\n",
        "[3] https://ieeexplore.ieee.org/document/5654484"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HaVwP0mpR4z4"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuB1SBIjR4z4",
        "outputId": "d7a53f06-f805-44e0-89fc-b21f72821b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (0.2.0.1)\n",
            "Requirement already satisfied: scipy in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.10.0)\n",
            "Requirement already satisfied: matplotlib in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (3.6.3)\n",
            "Requirement already satisfied: numpy in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.24.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.2.1)\n",
            "Requirement already satisfied: tqdm in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (4.65.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (0.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (23.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.7.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2021.7.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (1.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "%pip install lime\n",
        "import os\n",
        "import time\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.datasets import cifar100\n",
        "from keras.engine import training\n",
        "from keras.layers import VersionAwareLayers\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import data_utils, layer_utils, to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8PLVuZv_R4z6"
      },
      "outputs": [],
      "source": [
        "np.random.seed(77)\n",
        "tf.random.set_seed(77)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2ikqUiVgR4z6"
      },
      "outputs": [],
      "source": [
        "classes_dict = {\n",
        "    \"0\": ['apple'],\n",
        "    \"1\": ['aquarium_fish'],\n",
        "    \"2\": ['baby'],\n",
        "    \"3\": ['bear'],\n",
        "    \"4\": ['beaver'],\n",
        "    \"5\": ['bed'],\n",
        "    \"6\": ['bee'],\n",
        "    \"7\": ['beetle'],\n",
        "    \"8\": ['bicycle'],\n",
        "    \"9\": ['bottle'],\n",
        "    \"10\": ['bowl'],\n",
        "    \"11\": ['boy'],\n",
        "    \"12\": ['bridge'],\n",
        "    \"13\": ['bus'],\n",
        "    \"14\": ['butterfly'],\n",
        "    \"15\": ['camel'],\n",
        "    \"16\": ['can'],\n",
        "    \"17\": ['castle'],\n",
        "    \"18\": ['caterpillar'],\n",
        "    \"19\": ['cattle'],\n",
        "    \"20\": ['chair'],\n",
        "    \"21\": ['chimpanzee'],\n",
        "    \"22\": ['clock'],\n",
        "    \"23\": ['cloud'],\n",
        "    \"24\": ['cockroach'],\n",
        "    \"25\": ['couch'],\n",
        "    \"26\": ['crab'],\n",
        "    \"27\": ['crocodile'],\n",
        "    \"28\": ['cup'],\n",
        "    \"29\": ['dinosaur'],\n",
        "    \"30\": ['dolphin'],\n",
        "    \"31\": ['elephant'],\n",
        "    \"32\": ['flatfish'],\n",
        "    \"33\": ['forest'],\n",
        "    \"34\": ['fox'],\n",
        "    \"35\": ['girl'],\n",
        "    \"36\": ['hamster'],\n",
        "    \"37\": ['house'],\n",
        "    \"38\": ['kangaroo'],\n",
        "    \"39\": ['computer_keyboard'],\n",
        "    \"40\": ['lamp'],\n",
        "    \"41\": ['lawn_mower'],\n",
        "    \"42\": ['leopard'],\n",
        "    \"43\": ['lion'],\n",
        "    \"44\": ['lizard'],\n",
        "    \"45\": ['lobster'],\n",
        "    \"46\": ['man'],\n",
        "    \"47\": ['maple_tree'],\n",
        "    \"48\": ['motorcycle'],\n",
        "    \"49\": ['mountain'],\n",
        "    \"50\": ['mouse'],\n",
        "    \"51\": ['mushroom'],\n",
        "    \"52\": ['oak_tree'],\n",
        "    \"53\": ['orange'],\n",
        "    \"54\": ['orchid'],\n",
        "    \"55\": ['otter'],\n",
        "    \"56\": ['palm_tree'],\n",
        "    \"57\": ['pear'],\n",
        "    \"58\": ['pickup_truck'],\n",
        "    \"59\": ['pine_tree'],\n",
        "    \"60\": ['plain'],\n",
        "    \"61\": ['plate'],\n",
        "    \"62\": ['poppy'],\n",
        "    \"63\": ['porcupine'],\n",
        "    \"64\": ['possum'],\n",
        "    \"65\": ['rabbit'],\n",
        "    \"66\": ['raccoon'],\n",
        "    \"67\": ['ray'],\n",
        "    \"68\": ['road'],\n",
        "    \"69\": ['rocket'],\n",
        "    \"70\": ['rose'],\n",
        "    \"71\": ['sea'],\n",
        "    \"72\": ['seal'],\n",
        "    \"73\": ['shark'],\n",
        "    \"74\": ['shrew'],\n",
        "    \"75\": ['skunk'],\n",
        "    \"76\": ['skyscraper'],\n",
        "    \"77\": ['snail'],\n",
        "    \"78\": ['snake'],\n",
        "    \"79\": ['spider'],\n",
        "    \"80\": ['squirrel'],\n",
        "    \"81\": ['streetcar'],\n",
        "    \"82\": ['sunflower'],\n",
        "    \"83\": ['sweet_pepper'],\n",
        "    \"84\": ['table'],\n",
        "    \"85\": ['tank'],\n",
        "    \"86\": ['telephone'],\n",
        "    \"87\": ['television'],\n",
        "    \"88\": ['tiger'],\n",
        "    \"89\": ['tractor'],\n",
        "    \"90\": ['train'],\n",
        "    \"91\": ['trout'],\n",
        "    \"92\": ['tulip'],\n",
        "    \"93\": ['turtle'],\n",
        "    \"94\": ['wardrobe'],\n",
        "    \"95\": ['whale'],\n",
        "    \"96\": ['willow_tree'],\n",
        "    \"97\": ['wolf'],\n",
        "    \"98\": ['woman'],\n",
        "    \"99\": ['worm']\n",
        "}\n",
        "\n",
        "labels = [classes_dict[str(i)][0] for i in range(100)]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wv6Lb09bR4z7"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlhDjPO4R4z8",
        "outputId": "5cb86886-17ae-48b4-c38c-87fefdc2d131"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    test_size=0.7\n",
        ")\n",
        "\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "y_valid = to_categorical(y_valid, 100)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    height_shift_range=0.25,\n",
        "    width_shift_range=0.25,\n",
        "    shear_range=0.25,\n",
        "    zoom_range=0.25,\n",
        "    rotation_range=45,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B7TEc02uR4z8"
      },
      "source": [
        "# BPCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E6hqZ6fCR4z8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BPCAPooling(tf.keras.layers.Layer):\n",
        "    def __init__(self, pool_size=2, stride=2, n_components=1, expected_shape=None, **kwargs):\n",
        "        super(BPCAPooling, self).__init__(**kwargs)\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "        self.n_components = n_components\n",
        "        self.expected_shape = expected_shape\n",
        "\n",
        "        self.patch_size = [1, self.pool_size, self.pool_size, 1]\n",
        "        self.strides = [1, self.stride, self.stride, 1]\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(BPCAPooling, self).build(input_shape)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'pool_size': (self.pool_size, self.pool_size),\n",
        "            'strides': (self.stride, self.stride)\n",
        "        }\n",
        "        base_config = super(BPCAPooling, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @tf.function\n",
        "    def bpca_pooling(self,feature_map):\n",
        "        # Compute the region of interest\n",
        "        h, w, c = self.expected_shape  # block_height, block_width, block_channels\n",
        "        d = c // (self.pool_size * self.pool_size)  # block_depth\n",
        "\n",
        "        # Create blocks (patches)\n",
        "        data = tf.reshape(feature_map,[1, h, w, c])\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=data,\n",
        "            sizes=self.patch_size,\n",
        "            strides=self.strides,\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID'\n",
        "        )\n",
        "        patches = tf.reshape(\n",
        "            patches,\n",
        "            [h*w*d, self.pool_size * self.pool_size]\n",
        "        )\n",
        "\n",
        "        # Normalize the data by subtracting the mean and dividing by the standard deviation\n",
        "        mean = tf.reduce_mean(patches, axis=0)\n",
        "        std = tf.math.reduce_std(patches, axis=0)\n",
        "        patches = (patches - mean) / std\n",
        "        patches = tf.where(tf.math.is_nan(patches), 0.0, patches)\n",
        "\n",
        "        # Perform the Singular Value Decomposition (SVD) on the data\n",
        "        _, _, v = tf.linalg.svd(patches)\n",
        "\n",
        "        # Extract the first n principal components from the matrix v\n",
        "        pca_components = v[:, :self.n_components]\n",
        "\n",
        "        # Perform the PCA transformation on the data\n",
        "        transformed_patches = tf.matmul(patches, pca_components)\n",
        "        return tf.reshape(transformed_patches, [h // self.pool_size, w // self.pool_size, c])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        pooled = tf.vectorized_map(self.bpca_pooling, inputs)\n",
        "        return pooled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GlobalBPCAPooling(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_components=1, **kwargs):\n",
        "        super(GlobalBPCAPooling, self).__init__(**kwargs)\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(GlobalBPCAPooling, self).build(input_shape)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'n_components': self.n_components\n",
        "        }\n",
        "        base_config = super(GlobalBPCAPooling, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @tf.function\n",
        "    def bpca_pooling(self, feature_map):\n",
        "        # Flatten the feature map\n",
        "        patches = tf.reshape(feature_map, [-1, tf.shape(feature_map)[-1]])\n",
        "\n",
        "        # Normalize the data by subtracting the mean and dividing by the standard deviation\n",
        "        mean = tf.reduce_mean(patches, axis=0)\n",
        "        std = tf.math.reduce_std(patches, axis=0)\n",
        "        patches = (patches - mean) / std\n",
        "        patches = tf.where(tf.math.is_nan(patches), 0.0, patches)\n",
        "\n",
        "        # Perform the Singular Value Decomposition (SVD) on the data\n",
        "        _, _, v = tf.linalg.svd(patches)\n",
        "\n",
        "        # Extract the first n principal components from the matrix v\n",
        "        pca_components = v[:, :self.n_components]\n",
        "\n",
        "        # Perform the PCA transformation on the data\n",
        "        transformed_patches = tf.matmul(patches, pca_components)\n",
        "        return transformed_patches\n",
        "\n",
        "    def call(self, inputs):\n",
        "        pooled = tf.vectorized_map(self.bpca_pooling, inputs)\n",
        "        pooled = tf.reduce_mean(pooled, axis=0, keepdims=True)\n",
        "        return pooled\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ra3ZX5ZfR4z9"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rqRh7ZYxR4z9"
      },
      "outputs": [],
      "source": [
        "layers = VersionAwareLayers()\n",
        "WEIGHTS_PATH = (\n",
        "    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n",
        "    \"vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
        ")\n",
        "WEIGHTS_PATH_NO_TOP = (\n",
        "    \"https://storage.googleapis.com/tensorflow/\"\n",
        "    \"keras-applications/vgg16/\"\n",
        "    \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        ")\n",
        "\n",
        "\n",
        "def VGG16(include_top=True, weights=\"imagenet\", input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation=\"softmax\"):\n",
        "    if not (weights in {\"imagenet\", None} or tf.io.gfile.exists(weights)):\n",
        "        raise ValueError(\n",
        "            \"The `weights` argument should be either \"\n",
        "            \"`None` (random initialization), `imagenet` \"\n",
        "            \"(pre-training on ImageNet), \"\n",
        "            \"or the path to the weights file to be loaded.  Received: \"\n",
        "            f\"weights={weights}\"\n",
        "        )\n",
        "\n",
        "    if weights == \"imagenet\" and include_top and classes != 1000:\n",
        "        raise ValueError(\n",
        "            'If using `weights` as `\"imagenet\"` with `include_top` '\n",
        "            \"as true, `classes` should be 1000.  \"\n",
        "            f\"Received `classes={classes}`\"\n",
        "        )\n",
        "\n",
        "    input_shape = imagenet_utils.obtain_input_shape(\n",
        "        input_shape,\n",
        "        default_size=224,\n",
        "        min_size=32,\n",
        "        data_format=backend.image_data_format(),\n",
        "        require_flatten=include_top,\n",
        "        weights=weights,\n",
        "    )\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\")(img_input)\n",
        "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\")(x)\n",
        "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
        "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
        "    x = BPCAPooling(pool_size=2, stride=2, n_components=1, name=\"block1_pool\", expected_shape=(32, 32, 64))(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\")(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\")(x)\n",
        "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
        "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
        "    x = BPCAPooling(pool_size=2, stride=2, n_components=1, name=\"block2_pool\", expected_shape=(16, 16, 128))(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\")(x)\n",
        "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\")(x)\n",
        "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\")(x)\n",
        "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
        "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
        "    x = BPCAPooling(pool_size=2, stride=2, n_components=1, name=\"block3_pool\", expected_shape=(8, 8, 256))(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\")(x)\n",
        "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\")(x)\n",
        "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\")(x)\n",
        "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
        "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
        "    x = BPCAPooling(pool_size=2, stride=2, n_components=1, name=\"block4_pool\", expected_shape=(4, 4, 512))(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\")(x)\n",
        "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\")(x)\n",
        "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\")(x)\n",
        "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n",
        "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n",
        "    x = BPCAPooling(pool_size=2, stride=2, n_components=1, name=\"block5_pool\", expected_shape=(2, 2, 512))(x)\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = layers.Flatten(name=\"flatten\")(x)\n",
        "        x = layers.Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
        "        x = layers.Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n",
        "\n",
        "        imagenet_utils.validate_activation(classifier_activation, weights)\n",
        "        x = layers.Dense(\n",
        "            classes, activation=classifier_activation, name=\"predictions\"\n",
        "        )(x)\n",
        "    else:\n",
        "        if pooling == \"avg\":\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == \"max\":\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            x = GlobalBPCAPooling(n_components=1)(x)\n",
        "\n",
        "    if input_tensor is not None:\n",
        "        inputs = layer_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    vgg16_model = training.Model(inputs, x, name=\"vgg16\")\n",
        "\n",
        "    if weights == \"imagenet\":\n",
        "        if include_top:\n",
        "            weights_path = data_utils.get_file(\n",
        "                \"vgg16_weights_tf_dim_ordering_tf_kernels.h5\",\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir=\"models\",\n",
        "                file_hash=\"64373286793e3c8b2b4e3219cbf3544b\",\n",
        "            )\n",
        "        else:\n",
        "            weights_path = data_utils.get_file(\n",
        "                \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir=\"models\",\n",
        "                file_hash=\"6d6bbae143d832006294945121d1f1fc\",\n",
        "            )\n",
        "        vgg16_model.load_weights(weights_path)\n",
        "    elif weights is not None:\n",
        "        vgg16_model.load_weights(weights)\n",
        "\n",
        "    return vgg16_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pT8nVUSR4z-",
        "outputId": "b8bcb426-41c7-4fab-be1b-53a02e114abb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (BPCAPooling)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (BPCAPooling)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (BPCAPooling)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (BPCAPooling)   (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (BPCAPooling)   (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 512)              0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# VGG16\n",
        "vgg16_model = VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=X_train[0].shape,\n",
        "    classes=len(labels),\n",
        "    pooling=\"max\"\n",
        ")\n",
        "\n",
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-5VgfW4xe_d6",
        "outputId": "e75d43c5-2fde-412f-890d-3940b854b57f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(vgg16_model, expand_nested=True, dpi=60, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ3Oyu0CR4z_",
        "outputId": "c4fa4144-85ab-40e4-d330-0c044e476dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 <keras.engine.functional.Functional object at 0x7f9c9377a9a0>\n",
            "1 <keras.layers.core.dense.Dense object at 0x7f9d6711f5e0>\n",
            "2 <keras.layers.regularization.dropout.Dropout object at 0x7f9c937a1be0>\n",
            "3 <keras.layers.core.dense.Dense object at 0x7f9c937c1c70>\n",
            "4 <keras.layers.core.dense.Dense object at 0x7f9c9c664220>\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              2101248   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 100)               409700    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,006,948\n",
            "Trainable params: 19,292,260\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(vgg16_model)\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "model.add(layers.Dense(4096, activation=\"relu\", name=\"fc1\"))\n",
        "model.add(layers.Dropout(0.35))\n",
        "model.add(layers.Dense(4096, activation=\"relu\", name=\"fc2\"))\n",
        "model.add(layers.Dense(len(labels), activation='softmax', name=\"predictions\"))\n",
        "\n",
        "untrainable_layers = [0]\n",
        "for idx, layer in enumerate(model.layers):\n",
        "    print(idx, layer)\n",
        "    layer.trainable = False\n",
        "    if idx not in untrainable_layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "model.summary()\n",
        "vgg16_model = model\n",
        "del model\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jgKRYJG4R4z_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8Pg6yvFR4z_",
        "outputId": "6fce29ff-2885-4be7-a692-1c82998157c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:ModelCheckpoint mode bpca is unknown, fallback to auto mode.\n"
          ]
        }
      ],
      "source": [
        "model_checkpointer = ModelCheckpoint(\n",
        "    f'cifar100_vgg16_bpca_warmup.h5',\n",
        "    monitor='val_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='bpca'\n",
        ")\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-5)\n",
        "\n",
        "vgg16_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "history = vgg16_model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=128, shuffle=True),\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=1,\n",
        "    verbose=1,\n",
        "    callbacks=[\n",
        "        model_checkpointer\n",
        "    ]\n",
        ")\n",
        "end_time = time.perf_counter()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38WMaqfiU6Tl",
        "outputId": "2d0b88da-3144-4365-f355-dcf8853d863c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time 155.68262042800052\n"
          ]
        }
      ],
      "source": [
        "print(f\"Elapsed time {end_time-start_time}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "mestrado",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
