{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG_BPCA\n",
    "Here we are using a VGG net with 19 layers with the dataset cifar 100.\n",
    "\n",
    "We are trying to reproduce the results of the paper [1] changing the max pooling layers for blocked based principal component analysis (BPCA) layers like the article [2] proposes.\n",
    "\n",
    "[1] https://arxiv.org/pdf/1706.05350.pdf\n",
    "\n",
    "[2] http://www.ic.uff.br/iwssip2010/Proceedings/nav/papers/paper_10.pdf\n",
    "\n",
    "[3] https://ieeexplore.ieee.org/document/5654484"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lime in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (0.2.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.2.1)\n",
      "Requirement already satisfied: matplotlib in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (3.6.3)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (0.19.2)\n",
      "Requirement already satisfied: scipy in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.10.0)\n",
      "Requirement already satisfied: numpy in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (23.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2021.7.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.7.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lime\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import cifar100\n",
    "from keras.engine import training\n",
    "from keras.layers import VersionAwareLayers\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import data_utils, layer_utils, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(77)\n",
    "tf.random.set_seed(77)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = {\n",
    "    \"0\": ['apple'],\n",
    "    \"1\": ['aquarium_fish'],\n",
    "    \"2\": ['baby'],\n",
    "    \"3\": ['bear'],\n",
    "    \"4\": ['beaver'],\n",
    "    \"5\": ['bed'],\n",
    "    \"6\": ['bee'],\n",
    "    \"7\": ['beetle'],\n",
    "    \"8\": ['bicycle'],\n",
    "    \"9\": ['bottle'],\n",
    "    \"10\": ['bowl'],\n",
    "    \"11\": ['boy'],\n",
    "    \"12\": ['bridge'],\n",
    "    \"13\": ['bus'],\n",
    "    \"14\": ['butterfly'],\n",
    "    \"15\": ['camel'],\n",
    "    \"16\": ['can'],\n",
    "    \"17\": ['castle'],\n",
    "    \"18\": ['caterpillar'],\n",
    "    \"19\": ['cattle'],\n",
    "    \"20\": ['chair'],\n",
    "    \"21\": ['chimpanzee'],\n",
    "    \"22\": ['clock'],\n",
    "    \"23\": ['cloud'],\n",
    "    \"24\": ['cockroach'],\n",
    "    \"25\": ['couch'],\n",
    "    \"26\": ['crab'],\n",
    "    \"27\": ['crocodile'],\n",
    "    \"28\": ['cup'],\n",
    "    \"29\": ['dinosaur'],\n",
    "    \"30\": ['dolphin'],\n",
    "    \"31\": ['elephant'],\n",
    "    \"32\": ['flatfish'],\n",
    "    \"33\": ['forest'],\n",
    "    \"34\": ['fox'],\n",
    "    \"35\": ['girl'],\n",
    "    \"36\": ['hamster'],\n",
    "    \"37\": ['house'],\n",
    "    \"38\": ['kangaroo'],\n",
    "    \"39\": ['computer_keyboard'],\n",
    "    \"40\": ['lamp'],\n",
    "    \"41\": ['lawn_mower'],\n",
    "    \"42\": ['leopard'],\n",
    "    \"43\": ['lion'],\n",
    "    \"44\": ['lizard'],\n",
    "    \"45\": ['lobster'],\n",
    "    \"46\": ['man'],\n",
    "    \"47\": ['maple_tree'],\n",
    "    \"48\": ['motorcycle'],\n",
    "    \"49\": ['mountain'],\n",
    "    \"50\": ['mouse'],\n",
    "    \"51\": ['mushroom'],\n",
    "    \"52\": ['oak_tree'],\n",
    "    \"53\": ['orange'],\n",
    "    \"54\": ['orchid'],\n",
    "    \"55\": ['otter'],\n",
    "    \"56\": ['palm_tree'],\n",
    "    \"57\": ['pear'],\n",
    "    \"58\": ['pickup_truck'],\n",
    "    \"59\": ['pine_tree'],\n",
    "    \"60\": ['plain'],\n",
    "    \"61\": ['plate'],\n",
    "    \"62\": ['poppy'],\n",
    "    \"63\": ['porcupine'],\n",
    "    \"64\": ['possum'],\n",
    "    \"65\": ['rabbit'],\n",
    "    \"66\": ['raccoon'],\n",
    "    \"67\": ['ray'],\n",
    "    \"68\": ['road'],\n",
    "    \"69\": ['rocket'],\n",
    "    \"70\": ['rose'],\n",
    "    \"71\": ['sea'],\n",
    "    \"72\": ['seal'],\n",
    "    \"73\": ['shark'],\n",
    "    \"74\": ['shrew'],\n",
    "    \"75\": ['skunk'],\n",
    "    \"76\": ['skyscraper'],\n",
    "    \"77\": ['snail'],\n",
    "    \"78\": ['snake'],\n",
    "    \"79\": ['spider'],\n",
    "    \"80\": ['squirrel'],\n",
    "    \"81\": ['streetcar'],\n",
    "    \"82\": ['sunflower'],\n",
    "    \"83\": ['sweet_pepper'],\n",
    "    \"84\": ['table'],\n",
    "    \"85\": ['tank'],\n",
    "    \"86\": ['telephone'],\n",
    "    \"87\": ['television'],\n",
    "    \"88\": ['tiger'],\n",
    "    \"89\": ['tractor'],\n",
    "    \"90\": ['train'],\n",
    "    \"91\": ['trout'],\n",
    "    \"92\": ['tulip'],\n",
    "    \"93\": ['turtle'],\n",
    "    \"94\": ['wardrobe'],\n",
    "    \"95\": ['whale'],\n",
    "    \"96\": ['willow_tree'],\n",
    "    \"97\": ['wolf'],\n",
    "    \"98\": ['woman'],\n",
    "    \"99\": ['worm']\n",
    "}\n",
    "\n",
    "labels = [classes_dict[str(i)][0] for i in range(100)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=0.7\n",
    ")\n",
    "\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)\n",
    "y_valid = to_categorical(y_valid, 100)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    height_shift_range=0.25,\n",
    "    width_shift_range=0.25,\n",
    "    shear_range=0.25,\n",
    "    zoom_range=0.25,\n",
    "    rotation_range=45,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BPCALayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size=2, stride=2, n_components=1):\n",
    "        super(BPCALayer, self).__init__()\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def call(self, inputs):\n",
    "        def bpca_pooling(feature_map):\n",
    "            # print(feature_map.shape)\n",
    "\n",
    "            # Compute the region of interest\n",
    "            feature_map_height = int(feature_map.shape[0])\n",
    "            feature_map_width = int(feature_map.shape[1])\n",
    "            feature_map_channels = int(feature_map.shape[2])\n",
    "\n",
    "            h = feature_map_height\n",
    "            w = feature_map_width\n",
    "            c = feature_map_channels\n",
    "\n",
    "            # Create blocks (patches)\n",
    "            data = tf.reshape(\n",
    "                feature_map,\n",
    "                [1, feature_map_height, feature_map_width, feature_map_channels]\n",
    "            )\n",
    "            pool_size = self.pool_size\n",
    "            strides = self.stride\n",
    "\n",
    "            patch_size = [1, pool_size, pool_size, 1]\n",
    "            strides = [1, strides, strides, 1]\n",
    "            patches = tf.image.extract_patches(\n",
    "                images=data,\n",
    "                sizes=patch_size,\n",
    "                strides=strides,\n",
    "                rates=[1, 1, 1, 1],\n",
    "                padding='VALID'\n",
    "            )\n",
    "            d = c // (self.pool_size * self.pool_size)\n",
    "            data = tf.reshape(\n",
    "                patches,\n",
    "                [h*w*d, self.pool_size * self.pool_size]\n",
    "            )\n",
    "            # data = tf.reshape(patches, [h*w*8, 4])\n",
    "\n",
    "            # Normalize the data by subtracting the mean and dividing by the standard deviation\n",
    "            mean = tf.reduce_mean(data, axis=0)\n",
    "            std = tf.math.reduce_std(data, axis=0)\n",
    "            data = (data - mean) / std\n",
    "\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "\n",
    "            # Perform the Singular Value Decomposition (SVD) on the data\n",
    "            s, u, v = tf.linalg.svd(data)\n",
    "\n",
    "            # Extract the first n principal components from the matrix v\n",
    "            pca_components = v[:, :self.n_components]\n",
    "\n",
    "            # Perform the PCA transformation on the data\n",
    "            transformed_data = tf.matmul(data, pca_components)\n",
    "\n",
    "            return tf.reshape(transformed_data, [h // self.pool_size, w // self.pool_size, feature_map_channels])\n",
    "\n",
    "        pooled = tf.map_fn(bpca_pooling, inputs, dtype=tf.float32)\n",
    "        return pooled\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = VersionAwareLayers()\n",
    "WEIGHTS_PATH = (\n",
    "    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n",
    "    \"vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    ")\n",
    "WEIGHTS_PATH_NO_TOP = (\n",
    "    \"https://storage.googleapis.com/tensorflow/\"\n",
    "    \"keras-applications/vgg16/\"\n",
    "    \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    ")\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights=\"imagenet\", input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation=\"softmax\"):\n",
    "    if not (weights in {\"imagenet\", None} or tf.io.gfile.exists(weights)):\n",
    "        raise ValueError(\n",
    "            \"The `weights` argument should be either \"\n",
    "            \"`None` (random initialization), `imagenet` \"\n",
    "            \"(pre-training on ImageNet), \"\n",
    "            \"or the path to the weights file to be loaded.  Received: \"\n",
    "            f\"weights={weights}\"\n",
    "        )\n",
    "\n",
    "    if weights == \"imagenet\" and include_top and classes != 1000:\n",
    "        raise ValueError(\n",
    "            'If using `weights` as `\"imagenet\"` with `include_top` '\n",
    "            \"as true, `classes` should be 1000.  \"\n",
    "            f\"Received `classes={classes}`\"\n",
    "        )\n",
    "\n",
    "    input_shape = imagenet_utils.obtain_input_shape(\n",
    "        input_shape,\n",
    "        default_size=224,\n",
    "        min_size=32,\n",
    "        data_format=backend.image_data_format(),\n",
    "        require_flatten=include_top,\n",
    "        weights=weights,\n",
    "    )\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\")(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "    x = BPCALayer(pool_size=2, stride=2, n_components=1)(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\")(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "    x = BPCALayer(pool_size=2, stride=2, n_components=1)(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\")(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\")(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "    x = BPCALayer(pool_size=2, stride=2, n_components=1)(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "    x = BPCALayer(pool_size=2, stride=2, n_components=1)(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n",
    "    # x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n",
    "    x = BPCALayer(pool_size=2, stride=2, n_components=1)(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = layers.Flatten(name=\"flatten\")(x)\n",
    "        x = layers.Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
    "        x = layers.Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n",
    "\n",
    "        imagenet_utils.validate_activation(classifier_activation, weights)\n",
    "        x = layers.Dense(\n",
    "            classes, activation=classifier_activation, name=\"predictions\"\n",
    "        )(x)\n",
    "    else:\n",
    "        if pooling == \"avg\":\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == \"max\":\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "        else:\n",
    "            x = BPCALayer(pool_size=2, stride=2, n_components=1)(x)\n",
    "\n",
    "    if input_tensor is not None:\n",
    "        inputs = layer_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    vgg16_model = training.Model(inputs, x, name=\"vgg16\")\n",
    "\n",
    "    if weights == \"imagenet\":\n",
    "        if include_top:\n",
    "            weights_path = data_utils.get_file(\n",
    "                \"vgg16_weights_tf_dim_ordering_tf_kernels.h5\",\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir=\"models\",\n",
    "                file_hash=\"64373286793e3c8b2b4e3219cbf3544b\",\n",
    "            )\n",
    "        else:\n",
    "            weights_path = data_utils.get_file(\n",
    "                \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir=\"models\",\n",
    "                file_hash=\"6d6bbae143d832006294945121d1f1fc\",\n",
    "            )\n",
    "        vgg16_model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        vgg16_model.load_weights(weights)\n",
    "\n",
    "    return vgg16_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "(32, 32, 64)\n",
      "(16, 16, 128)\n",
      "(8, 8, 256)\n",
      "(4, 4, 512)\n",
      "(2, 2, 512)\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " bpca_layer (BPCALayer)      (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " bpca_layer_1 (BPCALayer)    (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " bpca_layer_2 (BPCALayer)    (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " bpca_layer_3 (BPCALayer)    (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " bpca_layer_4 (BPCALayer)    (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 512)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "vgg16_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=X_train[0].shape,\n",
    "    classes=len(labels),\n",
    "    pooling=\"max\"\n",
    ")\n",
    "\n",
    "vgg16_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 64)\n",
      "(16, 16, 128)\n",
      "(8, 8, 256)\n",
      "(4, 4, 512)\n",
      "(2, 2, 512)\n",
      "0 <keras.engine.functional.Functional object at 0x7fcdfe418130>\n",
      "1 <keras.layers.core.dense.Dense object at 0x7fcdfe3de0a0>\n",
      "2 <keras.layers.regularization.dropout.Dropout object at 0x7fcdfe414b50>\n",
      "3 <keras.layers.core.dense.Dense object at 0x7fcdfe485220>\n",
      "4 <keras.layers.core.dense.Dense object at 0x7fcdfe48f370>\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 512)               14714688  \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 100)               409700    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,006,948\n",
      "Trainable params: 19,292,260\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg16_model)\n",
    "# model.add(layers.Flatten(name=\"flatten\"))\n",
    "model.add(layers.Dense(4096, activation=\"relu\", name=\"fc1\"))\n",
    "model.add(layers.Dropout(0.35))\n",
    "model.add(layers.Dense(4096, activation=\"relu\", name=\"fc2\"))\n",
    "model.add(layers.Dense(len(labels), activation='softmax', name=\"predictions\"))\n",
    "\n",
    "untrainable_layers = [0]\n",
    "for idx, layer in enumerate(model.layers):\n",
    "    print(idx, layer)\n",
    "    layer.trainable = False\n",
    "    if idx not in untrainable_layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "model.summary()\n",
    "vgg16_model = model\n",
    "del model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(32, 32, 64)\n",
      "(16, 16, 128)\n",
      "(8, 8, 256)\n",
      "(4, 4, 512)\n",
      "(2, 2, 512)\n",
      "(32, 32, 64)\n",
      "(16, 16, 128)\n",
      "(8, 8, 256)\n",
      "(4, 4, 512)\n",
      "(2, 2, 512)\n",
      " 34/391 [=>............................] - ETA: 9:28 - loss: 4.6744 - accuracy: 0.0083"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m vgg16_model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     13\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m     15\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m---> 19\u001b[0m history \u001b[39m=\u001b[39m vgg16_model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     20\u001b[0m     datagen\u001b[39m.\u001b[39;49mflow(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     21\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_valid, y_valid),\n\u001b[1;32m     22\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     24\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     25\u001b[0m         model_checkpointer\n\u001b[1;32m     26\u001b[0m     ]\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_checkpointer = ModelCheckpoint(\n",
    "    f'cifar100_vgg16_bpca_warmup.h5',\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "vgg16_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "history = vgg16_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=128, shuffle=True),\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        model_checkpointer\n",
    "    ]\n",
    ")\n",
    "end_time = time.perf_counter()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
