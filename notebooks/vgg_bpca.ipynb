{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG_BPCA\n",
    "Here we are using a VGG net with 19 layers with the dataset cifar 100.\n",
    "\n",
    "We are trying to reproduce the results of the paper [1] changing the max pooling layers for blocked based principal component analysis (BPCA) layers like the article [2] proposes.\n",
    "\n",
    "[1] https://arxiv.org/pdf/1706.05350.pdf\n",
    "\n",
    "[2] http://www.ic.uff.br/iwssip2010/Proceedings/nav/papers/paper_10.pdf\n",
    "\n",
    "[3] https://ieeexplore.ieee.org/document/5654484"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lime in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (0.2.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.2.1)\n",
      "Requirement already satisfied: matplotlib in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (3.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (4.65.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (0.19.2)\n",
      "Requirement already satisfied: scipy in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.10.0)\n",
      "Requirement already satisfied: numpy in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from lime) (1.24.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.7.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2021.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (23.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from matplotlib->lime) (1.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/Users/brito/opt/anaconda3/envs/mestrado/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install lime\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import cifar100\n",
    "from keras.engine import training\n",
    "from keras.layers import VersionAwareLayers\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import data_utils, layer_utils, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(77)\n",
    "tf.random.set_seed(77)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = {\n",
    "    \"0\": ['apple'],\n",
    "    \"1\": ['aquarium_fish'],\n",
    "    \"2\": ['baby'],\n",
    "    \"3\": ['bear'],\n",
    "    \"4\": ['beaver'],\n",
    "    \"5\": ['bed'],\n",
    "    \"6\": ['bee'],\n",
    "    \"7\": ['beetle'],\n",
    "    \"8\": ['bicycle'],\n",
    "    \"9\": ['bottle'],\n",
    "    \"10\": ['bowl'],\n",
    "    \"11\": ['boy'],\n",
    "    \"12\": ['bridge'],\n",
    "    \"13\": ['bus'],\n",
    "    \"14\": ['butterfly'],\n",
    "    \"15\": ['camel'],\n",
    "    \"16\": ['can'],\n",
    "    \"17\": ['castle'],\n",
    "    \"18\": ['caterpillar'],\n",
    "    \"19\": ['cattle'],\n",
    "    \"20\": ['chair'],\n",
    "    \"21\": ['chimpanzee'],\n",
    "    \"22\": ['clock'],\n",
    "    \"23\": ['cloud'],\n",
    "    \"24\": ['cockroach'],\n",
    "    \"25\": ['couch'],\n",
    "    \"26\": ['crab'],\n",
    "    \"27\": ['crocodile'],\n",
    "    \"28\": ['cup'],\n",
    "    \"29\": ['dinosaur'],\n",
    "    \"30\": ['dolphin'],\n",
    "    \"31\": ['elephant'],\n",
    "    \"32\": ['flatfish'],\n",
    "    \"33\": ['forest'],\n",
    "    \"34\": ['fox'],\n",
    "    \"35\": ['girl'],\n",
    "    \"36\": ['hamster'],\n",
    "    \"37\": ['house'],\n",
    "    \"38\": ['kangaroo'],\n",
    "    \"39\": ['computer_keyboard'],\n",
    "    \"40\": ['lamp'],\n",
    "    \"41\": ['lawn_mower'],\n",
    "    \"42\": ['leopard'],\n",
    "    \"43\": ['lion'],\n",
    "    \"44\": ['lizard'],\n",
    "    \"45\": ['lobster'],\n",
    "    \"46\": ['man'],\n",
    "    \"47\": ['maple_tree'],\n",
    "    \"48\": ['motorcycle'],\n",
    "    \"49\": ['mountain'],\n",
    "    \"50\": ['mouse'],\n",
    "    \"51\": ['mushroom'],\n",
    "    \"52\": ['oak_tree'],\n",
    "    \"53\": ['orange'],\n",
    "    \"54\": ['orchid'],\n",
    "    \"55\": ['otter'],\n",
    "    \"56\": ['palm_tree'],\n",
    "    \"57\": ['pear'],\n",
    "    \"58\": ['pickup_truck'],\n",
    "    \"59\": ['pine_tree'],\n",
    "    \"60\": ['plain'],\n",
    "    \"61\": ['plate'],\n",
    "    \"62\": ['poppy'],\n",
    "    \"63\": ['porcupine'],\n",
    "    \"64\": ['possum'],\n",
    "    \"65\": ['rabbit'],\n",
    "    \"66\": ['raccoon'],\n",
    "    \"67\": ['ray'],\n",
    "    \"68\": ['road'],\n",
    "    \"69\": ['rocket'],\n",
    "    \"70\": ['rose'],\n",
    "    \"71\": ['sea'],\n",
    "    \"72\": ['seal'],\n",
    "    \"73\": ['shark'],\n",
    "    \"74\": ['shrew'],\n",
    "    \"75\": ['skunk'],\n",
    "    \"76\": ['skyscraper'],\n",
    "    \"77\": ['snail'],\n",
    "    \"78\": ['snake'],\n",
    "    \"79\": ['spider'],\n",
    "    \"80\": ['squirrel'],\n",
    "    \"81\": ['streetcar'],\n",
    "    \"82\": ['sunflower'],\n",
    "    \"83\": ['sweet_pepper'],\n",
    "    \"84\": ['table'],\n",
    "    \"85\": ['tank'],\n",
    "    \"86\": ['telephone'],\n",
    "    \"87\": ['television'],\n",
    "    \"88\": ['tiger'],\n",
    "    \"89\": ['tractor'],\n",
    "    \"90\": ['train'],\n",
    "    \"91\": ['trout'],\n",
    "    \"92\": ['tulip'],\n",
    "    \"93\": ['turtle'],\n",
    "    \"94\": ['wardrobe'],\n",
    "    \"95\": ['whale'],\n",
    "    \"96\": ['willow_tree'],\n",
    "    \"97\": ['wolf'],\n",
    "    \"98\": ['woman'],\n",
    "    \"99\": ['worm']\n",
    "}\n",
    "\n",
    "labels = [classes_dict[str(i)][0] for i in range(100)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=0.7\n",
    ")\n",
    "\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)\n",
    "y_valid = to_categorical(y_valid, 100)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    height_shift_range=0.25,\n",
    "    width_shift_range=0.25,\n",
    "    shear_range=0.25,\n",
    "    zoom_range=0.25,\n",
    "    rotation_range=45,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BPCALayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size=2, stride=2, n_components=1):\n",
    "        super(BPCALayer, self).__init__()\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def call(self, inputs):\n",
    "        def bpca_pooling(feature_map):\n",
    "            # Compute the region of interest\n",
    "            feature_map_height = int(feature_map.shape[0])\n",
    "            feature_map_width = int(feature_map.shape[1])\n",
    "            feature_map_channels = int(feature_map.shape[2])\n",
    "\n",
    "            h = feature_map_height\n",
    "            w = feature_map_width\n",
    "            c = feature_map_channels\n",
    "\n",
    "            # Create blocks (patches)\n",
    "            data = tf.reshape(\n",
    "                feature_map,\n",
    "                [1, feature_map_height, feature_map_width, feature_map_channels]\n",
    "            )\n",
    "            pool_size = self.pool_size\n",
    "            strides = self.stride\n",
    "\n",
    "            patch_size = [1, pool_size, pool_size, 1]\n",
    "            strides = [1, strides, strides, 1]\n",
    "            patches = tf.image.extract_patches(\n",
    "                images=data,\n",
    "                sizes=patch_size,\n",
    "                strides=strides,\n",
    "                rates=[1, 1, 1, 1],\n",
    "                padding='VALID'\n",
    "            )\n",
    "            d = c // (self.pool_size * self.pool_size)\n",
    "            data = tf.reshape(\n",
    "                patches,\n",
    "                [h*w*d, self.pool_size * self.pool_size]\n",
    "            )\n",
    "            # data = tf.reshape(patches, [h*w*8, 4])\n",
    "\n",
    "            # Normalize the data by subtracting the mean and dividing by the standard deviation\n",
    "            mean = tf.reduce_mean(data, axis=0)\n",
    "            std = tf.math.reduce_std(data, axis=0)\n",
    "            data = (data - mean) / std\n",
    "\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "\n",
    "            # Perform the Singular Value Decomposition (SVD) on the data\n",
    "            s, u, v = tf.linalg.svd(data)\n",
    "\n",
    "            # Extract the first n principal components from the matrix v\n",
    "            pca_components = v[:, :self.n_components]\n",
    "\n",
    "            # Perform the PCA transformation on the data\n",
    "            transformed_data = tf.matmul(data, pca_components)\n",
    "\n",
    "            return tf.reshape(transformed_data, [h // self.pool_size, w // self.pool_size, feature_map_channels])\n",
    "\n",
    "        pooled = tf.map_fn(bpca_pooling, inputs, dtype=tf.float32)\n",
    "        return pooled\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = VersionAwareLayers()\n",
    "WEIGHTS_PATH = (\n",
    "    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n",
    "    \"vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    ")\n",
    "WEIGHTS_PATH_NO_TOP = (\n",
    "    \"https://storage.googleapis.com/tensorflow/\"\n",
    "    \"keras-applications/vgg16/\"\n",
    "    \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    ")\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights=\"imagenet\", input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation=\"softmax\"):\n",
    "    if not (weights in {\"imagenet\", None} or tf.io.gfile.exists(weights)):\n",
    "        raise ValueError(\n",
    "            \"The `weights` argument should be either \"\n",
    "            \"`None` (random initialization), `imagenet` \"\n",
    "            \"(pre-training on ImageNet), \"\n",
    "            \"or the path to the weights file to be loaded.  Received: \"\n",
    "            f\"weights={weights}\"\n",
    "        )\n",
    "\n",
    "    if weights == \"imagenet\" and include_top and classes != 1000:\n",
    "        raise ValueError(\n",
    "            'If using `weights` as `\"imagenet\"` with `include_top` '\n",
    "            \"as true, `classes` should be 1000.  \"\n",
    "            f\"Received `classes={classes}`\"\n",
    "        )\n",
    "\n",
    "    input_shape = imagenet_utils.obtain_input_shape(\n",
    "        input_shape,\n",
    "        default_size=224,\n",
    "        min_size=32,\n",
    "        data_format=backend.image_data_format(),\n",
    "        require_flatten=include_top,\n",
    "        weights=weights,\n",
    "    )\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\")(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "    x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\")(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "    x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\")(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\")(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "    x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "    x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\")(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n",
    "    x = layers.AveragePooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = layers.Flatten(name=\"flatten\")(x)\n",
    "        x = layers.Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
    "        x = layers.Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n",
    "\n",
    "        imagenet_utils.validate_activation(classifier_activation, weights)\n",
    "        x = layers.Dense(\n",
    "            classes, activation=classifier_activation, name=\"predictions\"\n",
    "        )(x)\n",
    "    else:\n",
    "        if pooling == \"avg\":\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == \"max\":\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    if input_tensor is not None:\n",
    "        inputs = layer_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    vgg16_model = training.Model(inputs, x, name=\"vgg16\")\n",
    "\n",
    "    if weights == \"imagenet\":\n",
    "        if include_top:\n",
    "            weights_path = data_utils.get_file(\n",
    "                \"vgg16_weights_tf_dim_ordering_tf_kernels.h5\",\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir=\"models\",\n",
    "                file_hash=\"64373286793e3c8b2b4e3219cbf3544b\",\n",
    "            )\n",
    "        else:\n",
    "            weights_path = data_utils.get_file(\n",
    "                \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir=\"models\",\n",
    "                file_hash=\"6d6bbae143d832006294945121d1f1fc\",\n",
    "            )\n",
    "        vgg16_model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        vgg16_model.load_weights(weights)\n",
    "\n",
    "    return vgg16_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16\n",
    "vgg16_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=X_train[0].shape,\n",
    "    classes=len(labels),\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "\n",
    "vgg16_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg16_model)\n",
    "# model.add(layers.Flatten(name=\"flatten\"))\n",
    "model.add(layers.Dense(4096, activation=\"relu\", name=\"fc1\"))\n",
    "model.add(layers.Dropout(0.35))\n",
    "model.add(layers.Dense(4096, activation=\"relu\", name=\"fc2\"))\n",
    "model.add(layers.Dense(len(labels), activation='softmax', name=\"predictions\"))\n",
    "\n",
    "untrainable_layers = [0]\n",
    "for idx, layer in enumerate(model.layers):\n",
    "    print(idx, layer)\n",
    "    layer.trainable = False\n",
    "    if idx not in untrainable_layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "model.summary()\n",
    "vgg16_model = model\n",
    "del model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpointer = ModelCheckpoint(\n",
    "    f'cifar100_vgg16_bpca_warmup.h5',\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "vgg16_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "history = vgg16_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=128, shuffle=True),\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        model_checkpointer\n",
    "    ]\n",
    ")\n",
    "end_time = time.perf_counter()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
